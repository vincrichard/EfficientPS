MODEL:
  ANCHOR_GENERATOR:
    SIZES: [[32], [64], [128], [256]]  # One size for each in feature map
    ASPECT_RATIOS: [[0.5, 1.0, 2.0]]  # Three aspect ratios (same for all in feature maps)
  PROPOSAL_GENERATOR:
    NAME: "RPNCustom"
  RPN:
    HEAD_NAME: "DepthwiseSepRPNHead" # Normal RPN Head "StandardRPNHead"
    IN_FEATURES: ["P_4", "P_8", "P_16", "P_32"]
    PRE_NMS_TOPK_TRAIN: 2000  # Per FPN level
    PRE_NMS_TOPK_TEST: 2000  # Per FPN level
    BBOX_REG_LOSS_TYPE: "smooth_l1"
    BBOX_REG_LOSS_WEIGHT: 1.0
    SMOOTH_L1_BETA: 0.11111111 # 1.0 / 9.0

    # Detectron1 uses 2000 proposals per-batch,
    # (See "modeling/rpn/rpn_outputs.py" for details of this legacy issue)
    # which is approximately 1000 proposals per-image since the default batch size for FPN is 2.
    POST_NMS_TOPK_TRAIN: 1000
    POST_NMS_TOPK_TEST: 1000
    SMOOTH_L1_BETA: 0.1111
    IOU_THRESHOLDS: [0.3, 0.7]
  ROI_HEADS:
    NAME: "CustomROIHeads"
    # BATCH_SIZE_PER_IMAGE: 256 # number of proposals to sample for training
    # POSITIVE_FRACTION: 0.25 # fraction of positive (foreground) proposals to sample for training.
    IN_FEATURES: ["P_4", "P_8", "P_16", "P_32"]
    NUM_CLASSES: 8 # There is 8 instance in the city scape dataset
    # PROPOSAL_APPEND_GT:
    IOU_THRESHOLDS: [0.5]
    # IOU_LABELS:
    SCORE_THRESH_TEST: 0.5 # First step of panoptic fusion module
    NMS_THRESH_TEST: 0.5 # Second step of panoptic fusion module
  ROI_BOX_HEAD:
    POOLER_RESOLUTION: 7
    POOLER_SAMPLING_RATIO: 2 # (maybe put to 2) The `sampling_ratio` parameter for the ROIAlign op.
    POOLER_TYPE: "ROIAlign" # "ROIAlignV2"
    SMOOTH_L1_BETA: 1.0
    # SCORE_THRESH_TEST: 0.05
    # NMS_THRESH_TEST: 0.5
    BBOX_REG_LOSS_TYPE: "smooth_l1"
    SMOOTH_L1_BETA: 1.0
    BBOX_REG_LOSS_WEIGHT: 1.0
  ROI_MASK_HEAD:
    POOLER_RESOLUTION: 14
    POOLER_TYPE: "ROIAlign"
TEST:
  DETECTIONS_PER_IMAGE: 100

#### CUSTOM PARAMETER  #####

# DATA
DATASET_PATH: "/home/ubuntu/Elix/cityscapes"
#DATASET_PATH: "/media/vincent/C0FC3B20FC3B0FE0/Elix/detectron2/datasets/cityscapes"
TRAIN_JSON: "gtFine/cityscapes_panoptic_train.json"
VALID_JSON: "gtFine/cityscapes_panoptic_val.json"
PRED_DIR: "preds" # Path of images generated in the dataset folder
PRED_JSON: "cityscapes_panoptic_preds.json" # Path in the dataset folde of the prediction json created

# TRANSFORM
TRANSFORM:
  NORMALIZE:
    MEAN: (0.485, 0.456, 0.406)
    STD: (0.229, 0.224, 0.225)
  RESIZE:
    HEIGHT: 512
    WIDTH: 1024
  RANDOMCROP:
    HEIGHT: 512
    WIDTH: 1024
  HFLIP:
    PROB: 0.5
#   self.MEAN = [0.28689529, 0.32513294, 0.28389176]
#         self.STD = [0.17613647, 0.18099176, 0.17772235]
# 0.485, 0.456, 0.406) bizarre
        # CINAPTIC_STD = (0.229, 0.224, 0.225)
#         CITYSCAPES_MEAN = [0.28689554, 0.32513303, 0.28389177]
# CITYSCAPES_STD = [0.18696375, 0.19017339, 0.18720214]

# Solver
SOLVER:
  NAME: "Adam" # Adam or SGD
  BASE_LR: 0.007 #1.e-4
  WEIGHT_DECAY: 0.0001 # Only for SGD
  WARMUP_ITERS: 500 # Set to 0 for no warmup

CALLBACKS:
  CHECKPOINT_DIR: "logs/adam_lr_66e5"

# Path to load a model
CHECKPOINT_PATH: ""
BATCH_SIZE: 3
NUM_CLASS: 19
MODEL_CUSTOM:
  BACKBONE:
    EFFICIENTNET_ID: 5 # Id of the EfficienNet model  (Not the usual use in detectron2)
    LOAD_PRETRAIN: True # Load pretrain EfficienNet model
INFERENCE:
  AREA_TRESH: 512 #1024 / 2 because it's made on image of resize size